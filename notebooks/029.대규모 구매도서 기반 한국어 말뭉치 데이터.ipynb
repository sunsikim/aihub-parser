{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef18ca60-2601-4b0e-96a3-bfe1c82a65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import json\n",
    "import polars as pl\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "pl.Config.load_from_file(\"pl_config.json\")\n",
    "pl.set_random_seed(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c10fade-fe4e-4057-92fa-e7e5ff0e5943",
   "metadata": {},
   "source": [
    "## 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545f605-d99b-4be4-ae9d-6c811de396a9",
   "metadata": {},
   "source": [
    "다운받을 데이터셋 정보 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ac5194-5898-4fa1-8c9f-1de9d0eeeac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "aihubshell version 24.01.29 v0.3\n",
      "==========================================\n",
      "Fetching file tree structure...\n",
      "The contents are encoded in UTF-8 including Korean characters. \n",
      "If the following contents are not output normally, \n",
      "Please modify the character information of the OS. \n",
      "=================공지사항=================== \n",
      "========================================== \n",
      "\n",
      "    └─029.대규모 구매도서 기반 한국어 말뭉치 데이터\n",
      "        ├─01.데이터\n",
      "        │  ├─1.Training\n",
      "        │  │  ├─원천데이터\n",
      "        │  │  │  ├─TS_600.zip | 38 MB | 174654\n",
      "        │  │  │  ├─TS_320.zip | 896 MB | 174630\n",
      "        │  │  │  ├─TS_360.zip | 176 MB | 174631\n",
      "        │  │  │  ├─TS_370.zip | 125 MB | 174632\n",
      "        │  │  │  ├─TS_380.zip | 42 MB | 174633\n",
      "        │  │  │  ├─TS_390.zip | 27 MB | 174634\n",
      "        │  │  │  ├─TS_400.zip | 41 MB | 174635\n",
      "        │  │  │  ├─TS_410.zip | 17 MB | 174636\n",
      "        │  │  │  ├─TS_420.zip | 25 MB | 174637\n",
      "        │  │  │  ├─TS_430.zip | 6 MB | 174638\n",
      "        │  │  │  ├─TS_440.zip | 16 MB | 174639\n",
      "        │  │  │  ├─TS_450.zip | 10 MB | 174640\n",
      "        │  │  │  ├─TS_470.zip | 34 MB | 174641\n",
      "        │  │  │  ├─TS_480.zip | 6 MB | 174642\n",
      "        │  │  │  ├─TS_490.zip | 11 MB | 174643\n",
      "        │  │  │  ├─TS_500.zip | 7 MB | 174644\n",
      "        │  │  │  ├─TS_510.zip | 137 MB | 174645\n",
      "        │  │  │  ├─TS_520.zip | 21 MB | 174646\n",
      "        │  │  │  ├─TS_530.zip | 25 MB | 174647\n",
      "        │  │  │  ├─TS_540.zip | 9 MB | 174648\n",
      "        │  │  │  ├─TS_550.zip | 18 MB | 174649\n",
      "        │  │  │  ├─TS_560.zip | 10 MB | 174650\n",
      "        │  │  │  ├─TS_570.zip | 11 MB | 174651\n",
      "        │  │  │  ├─TS_580.zip | 3 MB | 174652\n",
      "        │  │  │  ├─TS_590.zip | 127 MB | 174653\n",
      "        │  │  │  ├─TS_820.zip | 14 MB | 174670\n",
      "        │  │  │  ├─TS_830.zip | 17 MB | 174671\n",
      "        │  │  │  ├─TS_840.zip | 35 MB | 174672\n",
      "        │  │  │  ├─TS_850.zip | 14 MB | 174673\n",
      "        │  │  │  ├─TS_860.zip | 9 MB | 174674\n",
      "        │  │  │  ├─TS_870.zip | 646 KB | 174675\n",
      "        │  │  │  ├─TS_880.zip | 611 KB | 174676\n",
      "        │  │  │  ├─TS_890.zip | 8 MB | 174677\n",
      "        │  │  │  ├─TS_900.zip | 74 MB | 174678\n",
      "        │  │  │  ├─TS_910.zip | 324 MB | 174679\n",
      "        │  │  │  ├─TS_920.zip | 53 MB | 174680\n",
      "        │  │  │  ├─TS_930.zip | 2 MB | 174681\n",
      "        │  │  │  ├─TS_940.zip | 14 MB | 174682\n",
      "        │  │  │  ├─TS_950.zip | 1 MB | 174683\n",
      "        │  │  │  ├─TS_960.zip | 83 KB | 174684\n",
      "        │  │  │  ├─TS_980.zip | 98 MB | 174685\n",
      "        │  │  │  ├─TS_990.zip | 42 MB | 174686\n",
      "        │  │  │  ├─TS_unscramble.zip | 1 GB | 174687\n",
      "        │  │  │  ├─TS_610.zip | 9 MB | 174655\n",
      "        │  │  │  ├─TS_620.zip | 931 KB | 174656\n",
      "        │  │  │  ├─TS_630.zip | 3 MB | 174657\n",
      "        │  │  │  ├─TS_640.zip | 1 MB | 174658\n",
      "        │  │  │  ├─TS_650.zip | 34 MB | 174659\n",
      "        │  │  │  ├─TS_660.zip | 7 MB | 174660\n",
      "        │  │  │  ├─TS_670.zip | 45 MB | 174661\n",
      "        │  │  │  ├─TS_680.zip | 44 MB | 174662\n",
      "        │  │  │  ├─TS_690.zip | 42 MB | 174663\n",
      "        │  │  │  ├─TS_700.zip | 18 MB | 174664\n",
      "        │  │  │  ├─TS_710.zip | 89 MB | 174665\n",
      "        │  │  │  ├─TS_730.zip | 73 KB | 174666\n",
      "        │  │  │  ├─TS_740.zip | 1 MB | 174667\n",
      "        │  │  │  ├─TS_800.zip | 134 MB | 174668\n",
      "        │  │  │  └─TS_810.zip | 2 GB | 174669\n",
      "        │  │  └─라벨링데이터\n",
      "        │  │      ├─TL_320.zip | 1 GB | 174572\n",
      "        │  │      ├─TL_360.zip | 220 MB | 174573\n",
      "        │  │      ├─TL_370.zip | 164 MB | 174574\n",
      "        │  │      ├─TL_380.zip | 54 MB | 174575\n",
      "        │  │      ├─TL_390.zip | 34 MB | 174576\n",
      "        │  │      ├─TL_400.zip | 53 MB | 174577\n",
      "        │  │      ├─TL_410.zip | 22 MB | 174578\n",
      "        │  │      ├─TL_420.zip | 32 MB | 174579\n",
      "        │  │      ├─TL_430.zip | 7 MB | 174580\n",
      "        │  │      ├─TL_440.zip | 20 MB | 174581\n",
      "        │  │      ├─TL_450.zip | 12 MB | 174582\n",
      "        │  │      ├─TL_470.zip | 43 MB | 174583\n",
      "        │  │      ├─TL_480.zip | 8 MB | 174584\n",
      "        │  │      ├─TL_490.zip | 15 MB | 174585\n",
      "        │  │      ├─TL_500.zip | 9 MB | 174586\n",
      "        │  │      ├─TL_510.zip | 178 MB | 174587\n",
      "        │  │      ├─TL_520.zip | 27 MB | 174588\n",
      "        │  │      ├─TL_530.zip | 32 MB | 174589\n",
      "        │  │      ├─TL_540.zip | 12 MB | 174590\n",
      "        │  │      ├─TL_550.zip | 24 MB | 174591\n",
      "        │  │      ├─TL_560.zip | 12 MB | 174592\n",
      "        │  │      ├─TL_570.zip | 15 MB | 174593\n",
      "        │  │      ├─TL_580.zip | 3 MB | 174594\n",
      "        │  │      ├─TL_590.zip | 172 MB | 174595\n",
      "        │  │      ├─TL_600.zip | 48 MB | 174596\n",
      "        │  │      ├─TL_610.zip | 11 MB | 174597\n",
      "        │  │      ├─TL_620.zip | 1 MB | 174598\n",
      "        │  │      ├─TL_630.zip | 4 MB | 174599\n",
      "        │  │      ├─TL_640.zip | 2 MB | 174600\n",
      "        │  │      ├─TL_650.zip | 43 MB | 174601\n",
      "        │  │      ├─TL_660.zip | 9 MB | 174602\n",
      "        │  │      ├─TL_670.zip | 58 MB | 174603\n",
      "        │  │      ├─TL_680.zip | 57 MB | 174604\n",
      "        │  │      ├─TL_690.zip | 55 MB | 174605\n",
      "        │  │      ├─TL_700.zip | 22 MB | 174606\n",
      "        │  │      ├─TL_710.zip | 117 MB | 174607\n",
      "        │  │      ├─TL_730.zip | 109 KB | 174608\n",
      "        │  │      ├─TL_740.zip | 2 MB | 174609\n",
      "        │  │      ├─TL_800.zip | 181 MB | 174610\n",
      "        │  │      ├─TL_810.zip | 3 GB | 174611\n",
      "        │  │      ├─TL_820.zip | 18 MB | 174612\n",
      "        │  │      ├─TL_830.zip | 23 MB | 174613\n",
      "        │  │      ├─TL_840.zip | 46 MB | 174614\n",
      "        │  │      ├─TL_850.zip | 19 MB | 174615\n",
      "        │  │      ├─TL_860.zip | 12 MB | 174616\n",
      "        │  │      ├─TL_870.zip | 862 KB | 174617\n",
      "        │  │      ├─TL_880.zip | 785 KB | 174618\n",
      "        │  │      ├─TL_890.zip | 11 MB | 174619\n",
      "        │  │      ├─TL_900.zip | 92 MB | 174620\n",
      "        │  │      ├─TL_910.zip | 410 MB | 174621\n",
      "        │  │      ├─TL_920.zip | 65 MB | 174622\n",
      "        │  │      ├─TL_930.zip | 2 MB | 174623\n",
      "        │  │      ├─TL_940.zip | 18 MB | 174624\n",
      "        │  │      ├─TL_950.zip | 2 MB | 174625\n",
      "        │  │      ├─TL_960.zip | 103 KB | 174626\n",
      "        │  │      ├─TL_980.zip | 125 MB | 174627\n",
      "        │  │      ├─TL_990.zip | 53 MB | 174628\n",
      "        │  │      └─TL_unscramble.zip | 1 GB | 174629\n",
      "        │  └─2.Validation\n",
      "        │      ├─라벨링데이터\n",
      "        │      │  ├─VL_060.zip | 132 KB | 174715\n",
      "        │      │  ├─VL_070.zip | 43 MB | 174716\n",
      "        │      │  ├─VL_080.zip | 15 MB | 174717\n",
      "        │      │  ├─VL_100.zip | 46 MB | 174718\n",
      "        │      │  ├─VL_110.zip | 9 MB | 174719\n",
      "        │      │  ├─VL_120.zip | 6 MB | 174720\n",
      "        │      │  ├─VL_130.zip | 4 MB | 174721\n",
      "        │      │  ├─VL_140.zip | 37 MB | 174722\n",
      "        │      │  ├─VL_150.zip | 105 MB | 174723\n",
      "        │      │  ├─VL_160.zip | 108 MB | 174724\n",
      "        │      │  ├─VL_170.zip | 4 MB | 174725\n",
      "        │      │  ├─VL_180.zip | 359 MB | 174726\n",
      "        │      │  ├─VL_190.zip | 183 MB | 174727\n",
      "        │      │  ├─VL_200.zip | 15 MB | 174728\n",
      "        │      │  ├─VL_unscramble.zip | 235 MB | 174729\n",
      "        │      │  ├─VL_020.zip | 68 MB | 174711\n",
      "        │      │  ├─VL_030.zip | 13 MB | 174712\n",
      "        │      │  ├─VL_040.zip | 20 MB | 174713\n",
      "        │      │  ├─VL_050.zip | 282 KB | 174714\n",
      "        │      │  ├─VL_010.zip | 21 MB | 174710\n",
      "        │      │  └─VL_000.zip | 106 MB | 174709\n",
      "        │      └─원천데이터\n",
      "        │          ├─VS_000.zip | 83 MB | 174688\n",
      "        │          ├─VS_010.zip | 16 MB | 174689\n",
      "        │          ├─VS_020.zip | 52 MB | 174690\n",
      "        │          ├─VS_030.zip | 11 MB | 174691\n",
      "        │          ├─VS_040.zip | 16 MB | 174692\n",
      "        │          ├─VS_050.zip | 226 KB | 174693\n",
      "        │          ├─VS_060.zip | 100 KB | 174694\n",
      "        │          ├─VS_070.zip | 35 MB | 174695\n",
      "        │          ├─VS_080.zip | 12 MB | 174696\n",
      "        │          ├─VS_100.zip | 36 MB | 174697\n",
      "        │          ├─VS_110.zip | 8 MB | 174698\n",
      "        │          ├─VS_120.zip | 5 MB | 174699\n",
      "        │          ├─VS_130.zip | 3 MB | 174700\n",
      "        │          ├─VS_140.zip | 28 MB | 174701\n",
      "        │          ├─VS_150.zip | 81 MB | 174702\n",
      "        │          ├─VS_160.zip | 86 MB | 174703\n",
      "        │          ├─VS_170.zip | 3 MB | 174704\n",
      "        │          ├─VS_180.zip | 270 MB | 174705\n",
      "        │          ├─VS_190.zip | 133 MB | 174706\n",
      "        │          ├─VS_200.zip | 12 MB | 174707\n",
      "        │          └─VS_unscramble.zip | 190 MB | 174708\n",
      "        ├─03.AI 모델\n",
      "        │  ├─AI 모델 소스코드.zip | 1 GB | 521260\n",
      "        │  └─AI 모델 환경 설치가이드.zip | 27 KB | 521261\n",
      "        └─02.저작도구\n",
      "            ├─저작도구 소스코드.zip | 16 KB | 397123\n",
      "            └─저작도구 설명서.zip | 2 MB | 397124\n"
     ]
    }
   ],
   "source": [
    "!aihubshell -mode l -datasetkey 653"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31ee30-082b-44c8-bfe4-cdc390b110b3",
   "metadata": {},
   "source": [
    "AI Hub 데이터셋 소개란에 기재된 [개요](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=653)를 살펴보고 내린 결정:\n",
    "\n",
    "* 책의 한 문단에 속하는 여러 문장들을 하나의 문서로 봐야한다. 원본 데이터에서는 그런 구조를 파싱하기 어려웠기 때문에 라벨링데이터를 활용한다.\n",
    "* 8로 시작하는 문학 텍스트는 아웃라이어같은 인물명을 가진 인물들 간 대화로 구성된 텍스트의 비중이 크다. 언어모델을 학습할 때 이처럼 특수한 데이터가 포함되는 것이 일반화 성능을 낮출 수 있으므로 제외한다.\n",
    "* 원문 텍스트(original_text)에는 한자 등 특수문자가 다수 포함된 텍스트 비중이 적지 않아서 이를 가공해 만든 문장 텍스트(text)를 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd7b4e-4c8d-401c-b88e-50c5b9d10f73",
   "metadata": {},
   "source": [
    "다운받은 데이터 디렉토리 및 결과 디렉토리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ff81c2-e562-4ffc-993b-f1d64af9d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_dir = [path for path in pathlib.Path(os.getcwd()).glob(\"*구매도서*\") if path.suffix != \".ipynb\"][0]\n",
    "result_dir = pathlib.Path(f\"{os.getcwd()}/aihub-datasets\")\n",
    "result_dir = result_dir.joinpath(archive_dir.name)\n",
    "if result_dir.exists():\n",
    "    os.system(f\"rm -rf {result_dir}\")\n",
    "result_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b43dc2-a81a-4512-b684-c2d36f39e83d",
   "metadata": {},
   "source": [
    "## 압축 해제 및 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d95fd-13f3-448b-b0a7-07a1d178422c",
   "metadata": {},
   "source": [
    "원천데이터 압축파일 경로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7ffd56-7455-4d97-9b9c-667eef67cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_paths = []\n",
    "for walk in os.walk(archive_dir):\n",
    "    current_path, folders, files = walk\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".zip\") and current_path.endswith(\"라벨링데이터\"):\n",
    "            archive_paths.append(f\"{current_path}/{file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef67f8-55a9-481f-9964-27f893a3ae4d",
   "metadata": {},
   "source": [
    "압축 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a2ebca-d2c5-4a77-8b61-e80c2a61a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for archive_path in archive_paths:\n",
    "    data_dir = pathlib.Path(archive_path.strip(\".zip\"))\n",
    "    shutil.unpack_archive(\n",
    "        filename=archive_path,\n",
    "        extract_dir=data_dir,\n",
    "        format=\"zip\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebd57a-fbde-45d8-a88a-fe1820cf71c3",
   "metadata": {},
   "source": [
    "각 데이터는 json 형태로 저장되어 있다. 파일 하나가 `paragraphs` 필드 밑에 하나 이상의 문장을 달고 있는 양상을 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f415c185-290b-4ea6-a6a5-589303e44356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in dataset : 2,460\n"
     ]
    }
   ],
   "source": [
    "data_files = list((archive_dir / \"01.데이터\").glob(\"*/라벨링데이터/[TV]L_[0-79]*/*TEXT*.json\"))\n",
    "data_files += list((archive_dir / \"01.데이터\").glob(\"*/라벨링데이터/[TV]L_unscramble/[0-79]*/*TEXT*.json\"))\n",
    "print(f\"Number of files in dataset : {len(data_files):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fce54-c581-4e2a-a0f9-d58f6d97245a",
   "metadata": {},
   "source": [
    "데이터 속성값들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023ad39f-a1ac-47d9-90e6-472835e4d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'BOOK_CORPUS_190.560001',\n",
      "  'info': {'author': {'birth_year': 1972,\n",
      "                      'jobs': ['연구원', '작가'],\n",
      "                      'write_age': 38},\n",
      "           'class': 0,\n",
      "           'kdc': '199',\n",
      "           'published_year': 2010},\n",
      "  'sentences': [{'char_count': 36,\n",
      "                 'id': 'BOOK_CORPUS_190.560001.1',\n",
      "                 'noise_ratio': 0.0,\n",
      "                 'original_text': '“실질적으로 ‘긍정’으로 가는 첫 단계는 바로 ‘정의하기’일세.”',\n",
      "                 'text': '“실질적으로 ‘긍정’으로 가는 첫 단계는 바로 ‘정의하기’일세.”',\n",
      "                 'word_count': 7}]},\n",
      " {'id': 'BOOK_CORPUS_190.560002',\n",
      "  'info': {'author': {'birth_year': 1967,\n",
      "                      'jobs': ['번역가', '작가'],\n",
      "                      'write_age': 48},\n",
      "           'class': 0,\n",
      "           'kdc': '199',\n",
      "           'published_year': 2015},\n",
      "  'sentences': [{'char_count': 51,\n",
      "                 'id': 'BOOK_CORPUS_190.560002.1',\n",
      "                 'noise_ratio': 0.0,\n",
      "                 'original_text': '다시 얼마 후 개사왕은 궁궐 밖으로 나갔다가 여러 백성이 악기를 만드는 모습을 '\n",
      "                                  '보고 물었다.',\n",
      "                 'text': '다시 얼마 후 개사왕은 궁궐 밖으로 나갔다가 여러 백성이 악기를 만드는 모습을 보고 물었다.',\n",
      "                 'word_count': 14}]},\n",
      " {'id': 'BOOK_CORPUS_190.560003',\n",
      "  'info': {'author': {'birth_year': 1928,\n",
      "                      'jobs': ['심리학자', '교수'],\n",
      "                      'write_age': 78},\n",
      "           'class': 1,\n",
      "           'kdc': '199',\n",
      "           'published_year': 2006},\n",
      "  'sentences': [{'char_count': 112,\n",
      "                 'id': 'BOOK_CORPUS_190.560003.1',\n",
      "                 'noise_ratio': 0.0,\n",
      "                 'original_text': '앞에 예로 든 대주교나 대도적의 경우도 그 후 주교가 자신의 지위를 누리며 '\n",
      "                                  '사치 삼매경에 빠졌을 수도 있고, 다른 한편으로 도적이 죄를 뉘우치고 나중에는 '\n",
      "                                  '가난하지만 성자와 같은 삶을 살았을지도 모른다.',\n",
      "                 'text': '앞에 예로 든 대주교나 대도적의 경우도 그 후 주교가 자신의 지위를 누리며 사치 삼매경에 '\n",
      "                         '빠졌을 수도 있고, 다른 한편으로 도적이 죄를 뉘우치고 나중에는 가난하지만 성자와 같은 삶을 '\n",
      "                         '살았을지도 모른다.',\n",
      "                 'word_count': 29},\n",
      "                {'char_count': 29,\n",
      "                 'id': 'BOOK_CORPUS_190.560003.2',\n",
      "                 'noise_ratio': 0.0,\n",
      "                 'original_text': '비슷해 보이는 운명이라도 그 가치는 너무나 달라진다.',\n",
      "                 'text': '비슷해 보이는 운명이라도 그 가치는 너무나 달라진다.',\n",
      "                 'word_count': 7}]}]\n"
     ]
    }
   ],
   "source": [
    "with open(data_files[0], \"r\") as file:\n",
    "    documents = json.load(file)[\"paragraphs\"]\n",
    "pprint(documents[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee08fa-8d28-4c8c-9614-7e04ea37813b",
   "metadata": {},
   "source": [
    "전체 로드. \n",
    "\n",
    "1. 만약 한 paragraphs 안에 여러 문장이 있으면 이를 공백을 경계로 이어붙인다.\n",
    "2. 10자 미만인 문장은 수집하지 않는다.\n",
    "3. 전체 데이터셋 용량이 꽤 크므로 파티션으로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1649f00c-89be-4987-9ec5-9d68304981ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2460/2460 [05:05<00:00,  8.06it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "partition_idx = 0\n",
    "for data_file in tqdm(data_files):\n",
    "    with open(data_file, \"r\") as file:\n",
    "        paragraphs = json.load(file)[\"paragraphs\"]\n",
    "    for paragraph in paragraphs:\n",
    "        sentences = [sentence[\"text\"] for sentence in paragraph[\"sentences\"]]  # (1a)\n",
    "        document = \" \".join(sentences)\n",
    "        if len(document) < 10:\n",
    "            continue  # (2)\n",
    "        else:\n",
    "            corpus.append(document)\n",
    "        if len(corpus) >= 1_000_000:  # (3)\n",
    "            partition = pl.DataFrame({\"document\": corpus})\n",
    "            partition.write_parquet(result_dir.joinpath(f\"partition_{partition_idx:02}.parquet\"))\n",
    "            partition_idx += 1\n",
    "            corpus = []\n",
    "if corpus:\n",
    "    partition = pl.DataFrame({\"document\": corpus})\n",
    "    partition.write_parquet(result_dir.joinpath(f\"partition_{partition_idx:02}.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6953c7-6661-4d3d-8280-669d625895d0",
   "metadata": {},
   "source": [
    "### 문서 토큰 수 분포 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8a4e0-04cf-4172-965c-82c86fdf3ac5",
   "metadata": {},
   "source": [
    "한국어에서는 정확히 적용되지 않지만, 편의를 위해 어절의 수(`공백 수 + 1`)를 토큰 수라고 정의한다. 문학 카테고리를 제외하고 수집해도 7억5천만개가 넘는 토큰을 확보할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0bdf94-c26e-4c43-8ff2-5380294291ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:24,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the corpus : 755,240,531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_tokens = []\n",
    "for partition_path in tqdm(result_dir.glob(\"*.parquet\")):\n",
    "    partition = pl.read_parquet(partition_path)\n",
    "    document_tokens = (\n",
    "        partition\n",
    "        .with_columns((pl.col(\"document\").str.count_matches(\" \") + 1).alias(\"num_tokens\"))\n",
    "        .to_dict(as_series=False)[\"num_tokens\"]\n",
    "    )\n",
    "    num_tokens.extend(document_tokens)\n",
    "print(f\"Number of tokens in the corpus : {sum(num_tokens):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882a398-7391-43db-baa8-cc3e7065f49e",
   "metadata": {},
   "source": [
    "문서당 토큰 수 분포. 이상치가 포함되어 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b945e798-e39e-4be5-bf8c-eb04f62abc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>min</th><th>q05</th><th>Q1</th><th>median</th><th>Q3</th><th>q95</th><th>max</th></tr><tr><td>i64</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>3</td><td>8</td><td>24</td><td>49</td><td>98</td><td>144,808</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "┌─────┬─────┬─────┬────────┬─────┬─────┬─────────┐\n",
       "│ min ┆ q05 ┆ Q1  ┆ median ┆ Q3  ┆ q95 ┆ max     │\n",
       "│ --- ┆ --- ┆ --- ┆ ---    ┆ --- ┆ --- ┆ ---     │\n",
       "│ i64 ┆ i32 ┆ i32 ┆ i32    ┆ i32 ┆ i32 ┆ i64     │\n",
       "╞═════╪═════╪═════╪════════╪═════╪═════╪═════════╡\n",
       "│ 1   ┆ 3   ┆ 8   ┆ 24     ┆ 49  ┆ 98  ┆ 144,808 │\n",
       "└─────┴─────┴─────┴────────┴─────┴─────┴─────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame({\"num_tokens\": num_tokens}).select(\n",
    "    pl.col(\"num_tokens\").min().alias(\"min\"),\n",
    "    pl.col(\"num_tokens\").quantile(0.05).cast(pl.Int32).alias(\"q05\"),\n",
    "    pl.col(\"num_tokens\").quantile(0.25).cast(pl.Int32).alias(\"Q1\"),\n",
    "    pl.col(\"num_tokens\").quantile(0.50).cast(pl.Int32).alias(\"median\"),\n",
    "    pl.col(\"num_tokens\").quantile(0.75).cast(pl.Int32).alias(\"Q3\"),\n",
    "    pl.col(\"num_tokens\").quantile(0.95).cast(pl.Int32).alias(\"q95\"),\n",
    "    pl.col(\"num_tokens\").max().alias(\"max\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
